{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14-deep-net-in-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNa2ruBJFLS9h0tekwqVxxY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduswiss/deep-learning-with-tensorflow/blob/master/notebooks/14_deep_net_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJIvu-6j2OsW"
      },
      "source": [
        "# Deep Neural Network in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kzxSPID2kS5"
      },
      "source": [
        "In this notebook, we adapt our TensorFlow Deep Net to PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNTbTy1T2nL4"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhdcHI52M7R"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBGmU-BP272c"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZZ1L-nG27KP"
      },
      "source": [
        "train = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test = MNIST('data', train=False, transform=transforms.ToTensor())\n",
        "# ...toTensor() scales pixels from [0, 255] to [0, 1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp-wy3p14sNU"
      },
      "source": [
        "## Batch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSme2EF04XL5"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True) \n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128) \n",
        "# ...DataLoader() can also sample and run multithreaded over a set number of workers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubxil-_W5JzN"
      },
      "source": [
        "## Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX3V6Idw5Ko0"
      },
      "source": [
        "n_input = 784\n",
        "n_dense_1 = 64\n",
        "n_dense_2 = 64\n",
        "n_dense_3 = 64\n",
        "n_out = 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03k-LT1a5GtI"
      },
      "source": [
        "model = nn.Sequential(\n",
        "\n",
        "    # first hidden layer\n",
        "    nn.Linear(n_input, n_dense_1),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    # second hidden layer\n",
        "    nn.Linear(n_dense_1, n_dense_2),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    # third hidden layer\n",
        "    nn.Linear(n_dense_2, n_dense_3),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(), \n",
        "\n",
        "    # output layer\n",
        "    nn.Linear(n_dense_3, n_out)\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJRkYd9o69Xn",
        "outputId": "d9e69fd8-1cde-4b5e-ca43-fc19832a2b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "summary(model, (1, n_input))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 64]          50,240\n",
            "              ReLU-2                [-1, 1, 64]               0\n",
            "            Linear-3                [-1, 1, 64]           4,160\n",
            "              ReLU-4                [-1, 1, 64]               0\n",
            "            Linear-5                [-1, 1, 64]           4,160\n",
            "              ReLU-6                [-1, 1, 64]               0\n",
            "           Dropout-7                [-1, 1, 64]               0\n",
            "            Linear-8                [-1, 1, 10]             650\n",
            "================================================================\n",
            "Total params: 59,210\n",
            "Trainable params: 59,210\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.23\n",
            "Estimated Total Size (MB): 0.23\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oruI3eUB7US0"
      },
      "source": [
        "## Configure training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKH0YCOb7FWP"
      },
      "source": [
        "cost_fxn = nn.CrossEntropyLoss() # includes softmax activation"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VNfsy657Y7C"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc0dZjfY7jAe"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUdkTOOF7cQ4"
      },
      "source": [
        "def accuracy_pct(pred_y, true_y):\n",
        "  _, prediction = torch.max(pred_y, 1) # returns maximum values, indices; fed tensor, dim to reduce\n",
        "  correct = (prediction == true_y).sum().item()\n",
        "  return (correct / true_y.shape[0]) * 100.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUiS4Bst7rpT",
        "outputId": "c8cfa170-fd16-4d0e-fb9c-c75974abe62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_batches = len(train_loader)\n",
        "n_batches"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbQUBKwN7t43",
        "outputId": "27b4b564-8819-40dc-f7d2-b9b3af6a1780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "n_epochs = 5\n",
        "\n",
        "\n",
        "print('Training for {} epochs. \\n'.format(n_epochs))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  avg_cost = 0.0\n",
        "  avg_accuracy = 0.0\n",
        "  \n",
        "  for i, (X, y) in enumerate(train_loader): # enumerate() provides count of iterations  \n",
        "    \n",
        "    # forward propagation:\n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_cost += cost / n_batches\n",
        "    \n",
        "    # backprop and optimization via gradient descent: \n",
        "    optimizer.zero_grad() # set gradients to zero; .backward() accumulates them in buffers\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # calculate accuracy metric:\n",
        "    accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_accuracy += accuracy / n_batches\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Step {}'.format(i + 1))\n",
        "    \n",
        "  print('Epoch {}/{} complete: Cost: {:.3f}, Accuracy: {:.1f}% \\n'\n",
        "        .format(epoch + 1, n_epochs, avg_cost, avg_accuracy)) \n",
        "\n",
        "print('Training complete.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 5 epochs. \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 1/5 complete: Cost: 0.642, Accuracy: 80.5% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 2/5 complete: Cost: 0.251, Accuracy: 93.2% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 3/5 complete: Cost: 0.185, Accuracy: 95.1% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 4/5 complete: Cost: 0.151, Accuracy: 95.9% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 5/5 complete: Cost: 0.125, Accuracy: 96.6% \n",
            "\n",
            "Training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzBTPyXuIHPg"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts3kY9wlGpOc",
        "outputId": "5d7c8fef-16a2-4436-c435-f7a7561824a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_test_batches = len(test_loader)\n",
        "n_test_batches"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQmRft2lIKMH",
        "outputId": "1ad33e6d-0a09-4d76-9aa9-eb7766867d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.eval() # disables dropout (and batch norm)\n",
        "\n",
        "with torch.no_grad(): # disables autograd, reducing memory consumption\n",
        "  \n",
        "  avg_test_cost = 0.0\n",
        "  avg_test_acc = 0.0\n",
        "  \n",
        "  for X, y in test_loader:\n",
        "    \n",
        "    # make predictions: \n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    \n",
        "    # calculate cost: \n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_test_cost += cost / n_test_batches\n",
        "    \n",
        "    # calculate accuracy:\n",
        "    test_accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_test_acc += test_accuracy / n_test_batches\n",
        "\n",
        "print('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))\n",
        "\n",
        "# model.train() # 'undoes' model.eval()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test cost: 0.105, Test accuracy: 97.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwNAjg3GIPTK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}